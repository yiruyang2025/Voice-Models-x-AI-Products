

```
# Cell 0: Imports and Seeds
import os
import random
import numpy as np
import librosa
import soundfile as sf
from glob import glob
from sklearn.model_selection import GroupShuffleSplit
from tensorflow.keras.utils import to_categorical
import tensorflow as tf

# reproducibility
SEED = 42
os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)
os.environ['TF_DETERMINISTIC_OPS'] = '1'
```



```
# Cell 1: Synthesize Base Cowbell Signals (no noise)
sr = 48000
duration = 5.0
n_samples = int(sr * duration)

class_specs = {
    "Swiss":   [(1000, 0.8), (2500, 0.3)],
    "Urban":   [(400, 0.7),  (1000, 0.4)],
    "Global":  [(200, 0.6),  (4000, 0.2)],
    "Unknown": [(300, 0.6),  (600, 0.4), (1200, 0.3)]
}

raw_signals = []
raw_labels = []
raw_ids = []

for label, specs in class_specs.items():
    for i in range(50):
        t = np.linspace(0, duration, n_samples, endpoint=False)
        signal = sum(amp * np.sin(2*np.pi*freq*t) for freq, amp in specs)
        signal *= np.hanning(n_samples)
        raw_signals.append(signal)
        raw_labels.append(label)
        raw_ids.append(f"{label}_{i}")
```


```
# Cell 2: Group Split into Train/Val/Test (no leakage)
groups = np.array(raw_ids)
gss = GroupShuffleSplit(n_splits=1, train_size=0.70, test_size=0.30, random_state=SEED)
train_idx, temp_idx = next(gss.split(raw_signals, raw_labels, groups))
# split the 30% left into val/test 50/50
temp_groups = groups[temp_idx]
gss2 = GroupShuffleSplit(n_splits=1, train_size=0.50, test_size=0.50, random_state=SEED)
val_rel, test_rel = next(gss2.split([None]*len(temp_idx), [None]*len(temp_idx), temp_groups))
val_idx = [temp_idx[i] for i in val_rel]
test_idx = [temp_idx[i] for i in test_rel]

idx_splits = {
    'train': train_idx,
    'val': val_idx,
    'test': test_idx
}
```


```
# Cell 2.4: Prepare Augmented Log-Mel Arrays for Training Split
import librosa
import numpy as np

labels = sorted(class_specs.keys())
label2idx = {lab: i for i, lab in enumerate(labels)}

X_train, y_train = [], []
for idx in idx_splits['train']:
    sig = raw_signals[idx]
    S = librosa.feature.melspectrogram(y=sig, sr=sr, n_fft=2048,
                                       hop_length=512, n_mels=64)
    S_dB = librosa.power_to_db(S, ref=np.max)
    X_train.append(S_dB[..., np.newaxis]) 
    y_train.append(label2idx[ raw_labels[idx] ])

# Cell 2.5: Visualize Original and Augmented Audio Spectrograms
import matplotlib.pyplot as plt
import librosa
import librosa.display
import numpy as np

# ---------- Helpers ----------
def estimate_semitone_shift(f_actual, f_ref):
    if not f_ref or not f_actual:
        return 0.0
    return np.round(12 * np.log2(f_actual / f_ref), 1)

def plot_log_mel_array(S_dB, title="", reference_freq=None, ax=None):
    global sr  # sampling rate must be defined
    if ax is None:
        fig, ax = plt.subplots(figsize=(8, 3))
    mel_freqs = librosa.mel_frequencies(n_mels=S_dB.shape[0], fmin=0, fmax=sr//2)
    f0_idx = np.argmax(S_dB.mean(axis=1))
    f0_freq = mel_freqs[f0_idx]
    shift = estimate_semitone_shift(f0_freq, reference_freq)
    librosa.display.specshow(
        S_dB, sr=sr, x_axis='time', y_axis='mel', ax=ax, cmap='magma'
    )
    ax.set_title(title)
    ax.axhline(f0_freq, color='cyan', ls='--', lw=1)
    ax.text(0.01, f0_freq+100, f"F0: {int(f0_freq)} Hz", color='cyan', fontsize=8)
    over_start = min(2*f0_freq, mel_freqs[-1])
    over_end = min(2*f0_freq+2000, mel_freqs[-1])
    ax.axhspan(over_start, over_end, color='yellow', alpha=0.3)
    ax.text(0.01, over_start+300, "Overtones", color='darkorange', fontsize=8)
    ax.text(0.7, 0.1*mel_freqs[-1],
            f"Shift: {shift:+.1f} st",
            fontsize=8, color='white',
            bbox=dict(facecolor='gray', alpha=0.5))
    return ax, f0_freq

# ---------- Original Samples ----------
reference_freqs = {}
fig, axes = plt.subplots(2, 2, figsize=(12, 8))
axes = axes.flatten()
for ax, label in zip(axes, sorted(class_specs.keys())):
    idx = raw_labels.index(label)
    signal = raw_signals[idx]
    S = librosa.feature.melspectrogram(y=signal, sr=sr, n_fft=2048,
                                       hop_length=512, n_mels=64)
    S_dB = librosa.power_to_db(S, ref=np.max)
    _, f0 = plot_log_mel_array(S_dB,
                               title=f"Original – {label}",
                               reference_freq=None,
                               ax=ax)
    reference_freqs[label] = f0

plt.suptitle("Original Samples – Log-Mel Spectrograms")
plt.tight_layout()
plt.show()

# ---------- Augmented Samples ----------
shown = set()
fig, axes = plt.subplots(2, 2, figsize=(12, 8))
axes = axes.flatten()

for mel_array, lbl in zip(X_train, y_train):
    label = labels[lbl]
    if label in shown:
        continue
    S_dB = mel_array.squeeze()  # shape [n_mels, time]
    ax = axes[len(shown)]
    plot_log_mel_array(S_dB,
                       title=f"Augmented – {label}",
                       reference_freq=reference_freqs[label],
                       ax=ax)
    shown.add(label)
    if len(shown) == len(labels):
        break

plt.suptitle("Augmented Samples – Log-Mel Spectrograms")
plt.tight_layout()
plt.show()
```


```
# Cell 3: Augmentation Functions
import librosa.effects

# load real noises once
noise_files = glob("real_noises/*.wav")
real_noises = [librosa.load(f, sr=sr)[0] for f in noise_files]

def add_white_noise(signal, snr_db):
    rms = np.sqrt(np.mean(signal**2))
    noise = np.random.randn(len(signal))
    noise *= rms * (10**(-snr_db/20)) / np.std(noise)
    return signal + noise

def mix_real_noise(signal):
    noise = random.choice(real_noises)
    if len(noise) < len(signal):
        noise = np.pad(noise, (0, len(signal)-len(noise)))
    else:
        start = random.randint(0, len(noise)-len(signal))
        noise = noise[start:start+len(signal)]
    snr_db = random.uniform(5, 20)
    return add_white_noise(noise, snr_db=snr_db) * 0.5 + signal * 0.5

def time_stretch(signal, sr):
    rate = random.uniform(0.9, 1.1)
    return librosa.effects.time_stretch(signal, rate=rate)[:n_samples]

def pitch_shift(signal, sr):
    n_steps = random.uniform(-2, 2)
    return librosa.effects.pitch_shift(signal, sr=sr, n_steps=n_steps)[:n_samples]

def spec_augment(mel, F=10, T=20, n_masks=2):
    m = mel.copy()
    M, L = m.shape
    for _ in range(n_masks):
        f0 = np.random.randint(0, M-F)
        t0 = np.random.randint(0, L-T)
        m[f0:f0+F, :] = 0
        m[:, t0:t0+T] = 0
    return m
```


```
# Cell 4: Build Datasets with Fixed-Size Augmentation & Feature Extraction
import numpy as np

_base_mel = extract_log_mel(raw_signals[idx_splits['train'][0]])
TARGET_FRAMES = _base_mel.shape[1] 

def pad_or_truncate(mel, target_frames=TARGET_FRAMES):
    """Pad with min dB or truncate on time axis to match target_frames."""
    n_mels, n_frames = mel.shape
    if n_frames < target_frames:
        pad_width = target_frames - n_frames
        pad = np.full((n_mels, pad_width), mel.min(), dtype=mel.dtype)
        return np.concatenate([mel, pad], axis=1)
    else:
        return mel[:, :target_frames]

def prepare_split(split_name, augment_times=5):
    X, y = [], []
    for idx in idx_splits[split_name]:
        base = raw_signals[idx]
        lbl = raw_labels[idx]
        mel = pad_or_truncate(extract_log_mel(base))
        X.append(mel[..., np.newaxis]); y.append(lbl)
        times = augment_times if split_name=='train' else 1
        for _ in range(times):
            sig = base.copy()
            if random.random() < 0.5:
                sig = add_white_noise(sig, snr_db=random.uniform(10,30))
            if real_noises and random.random() < 0.5:
                sig = mix_real_noise(sig)
            if random.random() < 0.5:
                sig = time_stretch(sig, sr)
            if random.random() < 0.5:
                sig = pitch_shift(sig, sr)
            mel_aug = extract_log_mel(sig)
            if split_name=='train' and random.random() < 0.5:
                mel_aug = spec_augment(mel_aug)
            mel_aug = pad_or_truncate(mel_aug)
            X.append(mel_aug[..., np.newaxis]); y.append(lbl)

    X = np.stack(X)  # now all shapes match
    y = np.array([labels.index(lbl) for lbl in y])
    return X, y

labels = sorted(class_specs.keys())
X_train, y_train = prepare_split('train', augment_times=5)
X_val,   y_val   = prepare_split('val',   augment_times=1)
X_test,  y_test  = prepare_split('test',  augment_times=1)

# one-hot
from tensorflow.keras.utils import to_categorical
y_train_cat = to_categorical(y_train, num_classes=len(labels))
y_val_cat   = to_categorical(y_val,   num_classes=len(labels))
y_test_cat  = to_categorical(y_test,  num_classes=len(labels))

print(f"Shapes: Train {X_train.shape}, Val {X_val.shape}, Test {X_test.shape}")
```



```
Shapes: Train (840, 64, 469, 1), Val (60, 64, 469, 1), Test (60, 64, 469, 1)
```


```
# Cell 4.5: Model Structure Visualization (Simplified & Clear)

from tensorflow.keras.utils import plot_model
from IPython.display import Image, display

# Save a simplified and clear model diagram
plot_model(
    model,
    to_file="model_architecture.png",
    show_shapes=True,          # Show tensor shapes for clarity
    show_layer_names=True,     # Show layer names
    rankdir='TB',              # Top-to-Bottom layout (better for compact models)
    expand_nested=False,       # No nested structure (flattened layout)
    dpi=120                    # Higher resolution for better rendering
)

# Display the image inline
display(Image(filename="model_architecture.png"))
```



```
```


```
```



