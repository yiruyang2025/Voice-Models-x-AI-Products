
```
# Cell 0: Install Required Packages
!pip install --quiet librosa soundfile numpy scipy scikit-learn matplotlib tensorflow

import os
import random
import numpy as np
if not hasattr(np, 'complex'):
    np.complex = np.complex128  # or just `complex`
import tensorflow as tf
import librosa
import librosa.display


# Set seeds for reproducibility
SEED = 42
os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# Optional: force TF deterministic behavior
os.environ['TF_DETERMINISTIC_OPS'] = '1'
```


```
# Cell 1: Synthesize Cowbell Audio with Noise Injection
import soundfile as sf

sr = 48000
duration = 5.0
n_samples = int(sr * duration)
out_dir = "cowbells"
os.makedirs(out_dir, exist_ok=True)

class_specs = {
    "Swiss":   ([(1000, 0.8), (2500, 0.3)], 50),
    "Urban":   ([(400, 0.7),  (1000, 0.4)], 50),
    "Global":  ([(200, 0.6),  (4000, 0.2)], 50),
    "Unknown": ([(300, 0.6),  (600, 0.4), (1200, 0.3)], 50)
}

def synthesize_and_save(label, specs, count):
    folder = os.path.join(out_dir, label)
    os.makedirs(folder, exist_ok=True)
    for i in range(count):
        t = np.linspace(0, duration, n_samples, endpoint=False)
        signal = sum(amp * np.sin(2*np.pi*freq*t) for freq, amp in specs)
        signal *= np.hanning(n_samples)
        # add white noise at random SNR between 10 and 30 dB
        noise = np.random.randn(n_samples)
        snr = np.random.uniform(10, 30)
        noise *= np.std(signal) * (10**(-snr/20))
        sf.write(os.path.join(folder, f"{label.lower()}_{i}.wav"), signal + noise, sr)

for lbl, (specs, cnt) in class_specs.items():
    synthesize_and_save(lbl, specs, cnt)
```


```
# Cell 2: Load, Pad, and Extract Log-Mel + SpecAugment
import librosa

def load_and_pad(path):
    y, _ = librosa.load(path, sr=sr)
    if len(y) < n_samples:
        y = np.pad(y, (0, n_samples - len(y)))
    else:
        y = y[:n_samples]
    return y

def extract_log_mel(y):
    S = librosa.feature.melspectrogram(
        y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=64
    )
    return librosa.power_to_db(S, ref=np.max)

def spec_augment(mel, F=10, T=20, n_masks=1):
    m = mel.copy()
    M, L = m.shape
    for _ in range(n_masks):
        f0 = np.random.randint(0, M - F)
        t0 = np.random.randint(0, L - T)
        m[f0:f0+F, :] = 0
        m[:, t0:t0+T] = 0
    return m

X, y = [], []
labels = sorted(os.listdir(out_dir))

for idx, lbl in enumerate(labels):
    folder = os.path.join(out_dir, lbl)
    for fn in os.listdir(folder):
        if not fn.endswith(".wav"):
            continue
        y_wave = load_and_pad(os.path.join(folder, fn))
        # 50% chance of spec augment
        mel = extract_log_mel(y_wave)
        if np.random.rand() < 0.5:
            mel = spec_augment(mel)
        X.append(mel)
        y.append(idx)

X = np.stack(X)[..., np.newaxis]
y = np.array(y)
```

```
# Cell 2.5: Visualize Original and Augmented Audio Spectrograms + Summary Table

import os
import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
import pandas as pd
from glob import glob
from IPython.display import display, Markdown

# ----------- Function to plot annotated log-mel spectrogram -----------

def plot_log_mel(filepath, title="Sample"):
    y, sr = librosa.load(filepath, sr=48000)
    if len(y) == 0:
        print(f"[Warning] Empty audio: {filepath}")
        return
    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=64)
    S_dB = librosa.power_to_db(S, ref=np.max)
    mel_freqs = librosa.mel_frequencies(n_mels=64)

    f0_idx = np.argmax(S.mean(axis=1))
    f0_freq = mel_freqs[f0_idx]

    plt.figure(figsize=(9, 4))
    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel', cmap='magma')
    plt.colorbar(format="%+2.0f dB")
    plt.title(title, fontsize=14)

    # Annotate: Fundamental frequency
    plt.axhline(y=f0_freq, color='cyan', linestyle='--', linewidth=1.2)
    plt.text(1, f0_freq + 800, "Fundamental", color='cyan', fontsize=10)

    # Annotate: Overtones / Resonance
    overtone_start = min(f0_freq * 2, mel_freqs[-1])
    overtone_end = min(f0_freq * 2 + 2000, mel_freqs[-1])
    plt.axhspan(overtone_start, overtone_end, color='yellow', alpha=0.3)
    plt.text(1, overtone_start + 1000, "Overtones / Resonance", color='darkorange', fontsize=10)

    # Add classification caption
    plt.text(0, -5, "Spectral distribution varies across classes – basis for classification.",
             fontsize=9, color='white', bbox=dict(facecolor='black', alpha=0.6))

    plt.tight_layout()
    plt.show()

# ----------- Plot original audio samples per class -----------

base_dir = "cowbells"
summary = []

if os.path.exists(base_dir):
    for cls in sorted(os.listdir(base_dir)):
        cls_path = os.path.join(base_dir, cls)
        if not os.path.isdir(cls_path): continue
        wavs = glob(os.path.join(cls_path, "*.wav"))
        summary.append({'Class': cls, 'Type': 'Original', 'Count': len(wavs)})
        if wavs:
            plot_log_mel(wavs[0], title=f"Original - {cls}")
        else:
            print(f"[Empty] No .wav files in {cls_path}")
else:
    print("[Skipped] Folder not found: cowbells")

# ----------- Visualize in-memory augmented log-mel spectrograms -----------

shown = set()
plt.figure(figsize=(12, 8))

for i in range(len(X)):
    label_idx = y[i]
    label_name = sorted(os.listdir(base_dir))[label_idx]
    if label_name in shown: continue

    plt.subplot(2, 2, len(shown) + 1)
    mel = X[i].squeeze()
    librosa.display.specshow(mel, sr=48000, x_axis='time', y_axis='mel', cmap='magma')
    plt.title(f"Augmented - {label_name}", fontsize=12)
    plt.colorbar(format="%+2.0f dB")

    mel_freqs = librosa.mel_frequencies(n_mels=64)
    f0_idx = np.argmax(mel.mean(axis=1))
    f0_freq = mel_freqs[f0_idx]
    overtone_start = min(f0_freq * 2, mel_freqs[-1])
    overtone_end = min(f0_freq * 2 + 2000, mel_freqs[-1])

    plt.axhline(y=f0_freq, color='cyan', linestyle='--', linewidth=1.2)
    plt.text(1, f0_freq + 800, "Fundamental", color='cyan', fontsize=9)
    plt.axhspan(overtone_start, overtone_end, color='yellow', alpha=0.3)
    plt.text(1, overtone_start + 1000, "Overtones / Resonance", color='darkorange', fontsize=9)
    plt.text(0, -5, "Spectral distribution varies – classification basis",
             fontsize=8, color='white', bbox=dict(facecolor='black', alpha=0.6))

    plt.tight_layout()
    shown.add(label_name)
    if len(shown) == 4: break

plt.suptitle("Augmented Samples - Log-Mel Spectrograms", fontsize=16)
plt.show()
```


```
# Cell 3: Stratified 70/15/15 Split + One-Hot
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

# Step 1: Split 15% Test set from total
X_remain, X_test, y_remain, y_test = train_test_split(
    X, y, test_size=0.15, stratify=y, random_state=42
)

# Step 2: From remaining 85%, split 15/85 ≈ 0.176 into validation
X_train, X_val, y_train, y_val = train_test_split(
    X_remain, y_remain, test_size=0.176, stratify=y_remain, random_state=42
)

# One-hot encode the labels
y_train_cat = to_categorical(y_train, num_classes=len(labels))
y_val_cat   = to_categorical(y_val,   num_classes=len(labels))
y_test_cat  = to_categorical(y_test,  num_classes=len(labels))

print(f"Train/Val/Test: {len(X_train)}/{len(X_val)}/{len(X_test)}")
```


```
Train/Val/Test: 560/120/120
```

```
# Cell 4: Build Lightweight CNN + 1×1 Adapter + Regularization (Improved)
from tensorflow.keras import layers, models, regularizers, optimizers, initializers

inp = layers.Input(shape=X_train.shape[1:])

# 1×1 adapter
x = layers.Conv2D(4, (1, 1), padding="same",
                  kernel_initializer='he_normal',
                  kernel_regularizer=regularizers.l2(1e-4))(inp)
x = layers.LeakyReLU()(x)

# First 3×3 Conv + Pool block
x = layers.Conv2D(8, (3, 3), padding="same",
                  kernel_initializer='he_normal',
                  kernel_regularizer=regularizers.l2(1e-4))(x)
x = layers.LeakyReLU()(x)
x = layers.MaxPooling2D((2, 2))(x)
x = layers.BatchNormalization()(x)

# Second 3×3 Conv + Pool block
x = layers.Conv2D(16, (3, 3), padding="same",
                  kernel_initializer='he_normal',
                  kernel_regularizer=regularizers.l2(1e-4))(x)
x = layers.LeakyReLU()(x)
x = layers.MaxPooling2D((2, 2))(x)
x = layers.BatchNormalization()(x)

# Global Average Pooling + classifier
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.4)(x)
out = layers.Dense(len(labels), activation="softmax",
                   kernel_regularizer=regularizers.l2(1e-4))(x)

model = models.Model(inputs=inp, outputs=out)
model.compile(
    optimizer=optimizers.Adam(1e-3),
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)
model.summary()
```

```
Model: "functional_8"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_8 (InputLayer)      │ (None, 64, 469, 1)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_24 (Conv2D)              │ (None, 64, 469, 4)     │             8 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ leaky_re_lu_9 (LeakyReLU)       │ (None, 64, 469, 4)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_25 (Conv2D)              │ (None, 64, 469, 8)     │           296 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ leaky_re_lu_10 (LeakyReLU)      │ (None, 64, 469, 8)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_16 (MaxPooling2D) │ (None, 32, 234, 8)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_16          │ (None, 32, 234, 8)     │            32 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_26 (Conv2D)              │ (None, 32, 234, 16)    │         1,168 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ leaky_re_lu_11 (LeakyReLU)      │ (None, 32, 234, 16)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_17 (MaxPooling2D) │ (None, 16, 117, 16)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_17          │ (None, 16, 117, 16)    │            64 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling2d_8      │ (None, 16)             │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_8 (Dropout)             │ (None, 16)             │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_8 (Dense)                 │ (None, 4)              │            68 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 1,636 (6.39 KB)
 Trainable params: 1,588 (6.20 KB)
 Non-trainable params: 48 (192.00 B)
```

```
# Cell 4.5: Model Structure Visualization (Simplified & Clear)

from tensorflow.keras.utils import plot_model
from IPython.display import Image, display

# Save a simplified and clear model diagram
plot_model(
    model,
    to_file="model_architecture.png",
    show_shapes=True,          # Show tensor shapes for clarity
    show_layer_names=True,     # Show layer names
    rankdir='TB',              # Top-to-Bottom layout (better for compact models)
    expand_nested=False,       # No nested structure (flattened layout)
    dpi=120                    # Higher resolution for better rendering
)

# Display the image inline
display(Image(filename="model_architecture.png"))
```


```
# Cell 5: Compute Class Weights, Train with EarlyStopping and ReduceLROnPlateau
from sklearn.utils import class_weight
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback
from tensorflow.keras import backend as K
import tensorflow as tf

# Step 1: Compute class weights based on label imbalance
cw = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.arange(len(labels)),
    y=y_train
)
cw_dict = dict(enumerate(cw))

# Manual tuning for important classes
cw_dict[labels.index("Swiss")] = 4.0
cw_dict[labels.index("Urban")] = 3.0
cw_dict[labels.index("Global")] = 2.0
cw_dict[labels.index("Unknown")] = 1.5
print("Adjusted class weights:", cw_dict)

# Step 2: Callback to log learning rate per epoch
class PrintLR(Callback):
    def on_epoch_end(self, epoch, logs=None):
        lr = self.model.optimizer.learning_rate.numpy()
        print(f"Learning rate at epoch {epoch + 1}: {lr:.6f}")

# Step 3: EarlyStopping based on validation loss
early = EarlyStopping(
    monitor="val_loss",
    mode="min",
    patience=8,
    restore_best_weights=True,
    verbose=1
)

# Step 4: Reduce learning rate on plateau
reduce_lr = ReduceLROnPlateau(
    monitor="val_loss",
    factor=0.6,
    patience=4,
    min_lr=5e-5,
    verbose=1
)

# Step 5: Train the model
history = model.fit(
    X_train, y_train_cat,
    validation_data=(X_val, y_val_cat),
    epochs=60,
    batch_size=32,
    class_weight=cw_dict,
    callbacks=[early, reduce_lr, PrintLR()],
    verbose=2
)

# Step 6: Print best epoch's performance
best_epoch = np.argmin(history.history['val_loss'])
print(f"\nBest epoch: {best_epoch + 1}")
print(f"Training  - Accuracy: {history.history['accuracy'][best_epoch]:.4f}, Loss: {history.history['loss'][best_epoch]:.4f}")
print(f"Validation - Accuracy: {history.history['val_accuracy'][best_epoch]:.4f}, Loss: {history.history['val_loss'][best_epoch]:.4f}")
```


```
Epoch 1/60
24/24 - 6s - 258ms/step - accuracy: 0.4052 - loss: 6.2515 - val_accuracy: 0.3676 - val_loss: 1.2904
Epoch 2/60
24/24 - 4s - 181ms/step - accuracy: 0.5817 - loss: 5.4544 - val_accuracy: 0.4265 - val_loss: 1.2533
Epoch 3/60
24/24 - 4s - 172ms/step - accuracy: 0.6183 - loss: 4.8862 - val_accuracy: 0.3235 - val_loss: 1.1083
Epoch 4/60
24/24 - 4s - 159ms/step - accuracy: 0.6471 - loss: 4.3749 - val_accuracy: 0.4485 - val_loss: 1.1101
Epoch 5/60
24/24 - 4s - 161ms/step - accuracy: 0.6876 - loss: 4.0147 - val_accuracy: 0.6029 - val_loss: 0.9610
Epoch 6/60
24/24 - 4s - 158ms/step - accuracy: 0.6915 - loss: 3.7419 - val_accuracy: 0.8309 - val_loss: 1.0172
Epoch 7/60
24/24 - 4s - 156ms/step - accuracy: 0.6824 - loss: 3.4911 - val_accuracy: 0.6471 - val_loss: 0.9444
Epoch 8/60
24/24 - 4s - 162ms/step - accuracy: 0.7150 - loss: 3.2070 - val_accuracy: 0.6397 - val_loss: 0.9577
Epoch 9/60
24/24 - 4s - 165ms/step - accuracy: 0.7098 - loss: 3.0157 - val_accuracy: 0.3088 - val_loss: 1.2412
Epoch 10/60
24/24 - 4s - 155ms/step - accuracy: 0.7281 - loss: 2.8508 - val_accuracy: 0.5882 - val_loss: 0.9905
Epoch 11/60
24/24 - 4s - 161ms/step - accuracy: 0.7190 - loss: 2.7658 - val_accuracy: 0.5588 - val_loss: 0.9817
Epoch 12/60
24/24 - 4s - 156ms/step - accuracy: 0.7412 - loss: 2.5968 - val_accuracy: 0.5147 - val_loss: 0.9514
Epoch 13/60
24/24 - 4s - 159ms/step - accuracy: 0.7699 - loss: 2.4086 - val_accuracy: 0.5809 - val_loss: 0.8626
Epoch 14/60
24/24 - 4s - 162ms/step - accuracy: 0.7660 - loss: 2.3818 - val_accuracy: 0.7721 - val_loss: 0.8013
Epoch 14: early stopping
Restoring model weights from the end of the best epoch: 6.
```


```
# Cell 6: Evaluate via Balanced Accuracy & Confusion Matrix
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score
import tensorflow as tf

@tf.function(reduce_retracing=True)
def predict_fn(x):
    return model(x, training=False)

y_pred = predict_fn(X_test).numpy().argmax(axis=1)
y_true = y_test

print("\nClassification Report:\n")
print(classification_report(y_true, y_pred, target_names=labels))
print(f"Balanced accuracy: {balanced_accuracy_score(y_true, y_pred):.3f}")

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(4,3))
plt.imshow(cm, cmap="Blues")
plt.xticks(range(len(labels)), labels, rotation=45)
plt.yticks(range(len(labels)), labels)
plt.colorbar()
plt.title("Confusion Matrix")
plt.tight_layout()
plt.show()
```


```

Classification Report:

              precision    recall  f1-score   support

      Global       0.94      1.00      0.97        30
       Swiss       0.94      0.97      0.95        30
     Unknown       1.00      0.93      0.97        30
       Urban       0.97      0.93      0.95        30

    accuracy                           0.96       120
   macro avg       0.96      0.96      0.96       120
weighted avg       0.96      0.96      0.96       120

Balanced accuracy: 0.958
```

```
# Cell 7: Demo Interface via File Upload
import numpy as np
import librosa
import ipywidgets as widgets
import matplotlib.pyplot as plt
from IPython.display import display, Audio

# Upload widget for multiple files
uploader = widgets.FileUpload(
    accept='.wav,.mp3',
    multiple=True,
    description='Upload Cowbell Audio'
)
output = widgets.Output()

def preprocess_audio(data: bytes):
    # load bytes buffer with librosa
    import io
    y, _ = librosa.load(io.BytesIO(data), sr=sr, mono=True)
    if len(y) < n_samples:
        y = np.pad(y, (0, n_samples - len(y)))
    else:
        y = y[:n_samples]
    mel = extract_log_mel(y)
    return mel[..., np.newaxis]

def on_upload_change(change):
    with output:
        output.clear_output()
        for filename, fileinfo in uploader.value.items():
            print(f"=== {filename} ===")
            display(Audio(data=fileinfo['content'], rate=sr))
            mel = preprocess_audio(fileinfo['content'])
            probs = predict_fn(mel[np.newaxis, ...]).numpy()[0]
            for cls, p in zip(labels, probs):
                print(f"{cls}: {p:.4f}")
            # bar plot
            plt.figure(figsize=(5,2))
            plt.bar(labels, probs)
            plt.ylim(0,1)
            plt.title(f"Probabilities for {filename}")
            plt.xticks(rotation=45)
            plt.show()

uploader.observe(on_upload_change, names='value')
display(uploader, output)
```


```

```


```

```




```
@article{yiruyang2025,
  title={Pick Veo 3},
  author={Yiru Yang},
  journal={arXiv preprint arXiv:2505.xxxxx},
  year={2025}
}
```

